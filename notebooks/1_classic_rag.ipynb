{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 1 \u00b7 Classic RAG Baseline\n",
        "\n",
        "This notebook re-creates the foundational retrieval-augmented generation (RAG) setup that powers the `example_app/` CLI. You will:\n",
        "\n",
        "1. Load the FAISS vector store that indexes the NimbusWorkspaces help center.\n",
        "2. Compose a `RetrievalQA` chain that fetches documents and synthesises an answer with `gpt-4.1-mini`.\n",
        "3. Inspect latency and retrieved sources to build intuition for later agentic extensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> \u2139\ufe0f **Pre-requisite** \u2014 run `python example_app/ingest.py` before executing the cells so the FAISS store is available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": [
        "from pprint import pprint\n",
        "\n",
        "from shared import (\n",
        "    DEFAULT_MODEL,\n",
        "    RetrievalContext,\n",
        "    build_baseline_chain,\n",
        "    build_retrieval_context,\n",
        "    pretty_print_json,\n",
        "    time_execution,\n",
        ")\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": [
        "context: RetrievalContext = build_retrieval_context(top_k=4)\n",
        "chain = build_baseline_chain(context.retriever)\n",
        "print(f\"Using chat model: {DEFAULT_MODEL}\")\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": [
        "question = \"How can I reset the admin password for my workspace?\"\n",
        "\n",
        "result_payload = time_execution(chain.invoke, {\"query\": question})\n",
        "print(f\"Elapsed: {result_payload['elapsed_seconds']:.2f}s\")\n",
        "answer = result_payload[\"result\"][\"result\"]\n",
        "print(answer)\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": [
        "retrieved_docs = context.retriever.get_relevant_documents(question)\n",
        "print(f\"Top {len(retrieved_docs)} supporting documents:\")\n",
        "for idx, doc in enumerate(retrieved_docs, start=1):\n",
        "    title = doc.metadata.get(\"title\") or doc.metadata.get(\"source\", \"doc\")\n",
        "    snippet = doc.page_content[:400].replace('\\n', ' ')\n",
        "    print(f\"\\n[{idx}] {title}\n",
        "{snippet}...\")\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection\n",
        "\n",
        "* Does the retrieved evidence fully answer the question?\n",
        "* What happens if you increase `top_k` or change the question phrasing?\n",
        "* Try swapping the model to `gpt-4.1-mini` or `gpt-4.1` for a quality comparison."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
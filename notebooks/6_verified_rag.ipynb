{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 6 \u00b7 Verified RAG\n",
        "\n",
        "This notebook attaches a verification stage that checks generated claims against secondary retrieval evidence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": [
        "from typing import Dict\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI as LangChainChatOpenAI\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "from shared import (\n",
        "    DEFAULT_MODEL,\n",
        "    RetrievalContext,\n",
        "    build_baseline_chain,\n",
        "    build_retrieval_context,\n",
        "    pretty_print_json,\n",
        "    time_execution,\n",
        ")\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": [
        "context = build_retrieval_context(top_k=4)\n",
        "qa_chain = build_baseline_chain(context.retriever)\n",
        "verifier_llm = LangChainChatOpenAI(model=DEFAULT_MODEL, temperature=0.0)\n",
        "verification_prompt = PromptTemplate.from_template(\n",
        "    'Statement: {statement}\\nEvidence: {evidence}\\n\\nIs the statement fully supported by the evidence? Reply with SUPPORTED, PARTIAL, or UNSUPPORTED and explain.'\n",
        ")\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": [
        "def answer_with_verification(question: str) -> Dict[str, str]:\n",
        "    docs = context.retriever.get_relevant_documents(question)\n",
        "    evidence = '\\n\\n'.join(doc.page_content for doc in docs)\n",
        "    answer = qa_chain.run(question)\n",
        "    verdict = verifier_llm.predict(verification_prompt.format(statement=answer, evidence=evidence))\n",
        "    return {'answer': answer, 'verdict': verdict}\n",
        "\n",
        "result = answer_with_verification('Summarise the security features included in the Enterprise plan.')\n",
        "print(result['answer'] + '\\n\\nVerification verdict: ' + result['verdict'])\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next steps\n",
        "\n",
        "* Implement granular claim extraction before verification.\n",
        "* Route UNSUPPORTED claims back to the retriever for additional sourcing.\n",
        "* Log verification outcomes to build observability dashboards."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}